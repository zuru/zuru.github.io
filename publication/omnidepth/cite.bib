@InProceedings{zioulis2018omnidepth,
    author="Zioulis, Nikolaos
    and Karakottas, Antonis
    and Zarpalas, Dimitrios
    and Daras, Petros",
    editor="Ferrari, Vittorio
    and Hebert, Martial
    and Sminchisescu, Cristian
    and Weiss, Yair",
    title="OmniDepth: Dense Depth Estimation for Indoors Spherical Panoramas",
    booktitle="Computer Vision -- ECCV 2018",
    year="2018",
    publisher="Springer International Publishing",
    address="Cham",
    pages="453--471",
    abstract="Recent work on depth estimation up to now has only focused on projective images ignoring {\$}{\$}{\{}360{\}}^{\{}{\backslash}circ {\}}{\$}{\$}content which is now increasingly and more easily produced. We show that monocular depth estimation models trained on traditional images produce sub-optimal results on omnidirectional images, showcasing the need for training directly on {\$}{\$}{\{}360{\}}^{\{}{\backslash}circ {\}}{\$}{\$}datasets, which however, are hard to acquire. In this work, we circumvent the challenges associated with acquiring high quality {\$}{\$}{\{}360{\}}^{\{}{\backslash}circ {\}}{\$}{\$}datasets with ground truth depth annotations, by re-using recently released large scale 3D datasets and re-purposing them to {\$}{\$}{\{}360{\}}^{\{}{\backslash}circ {\}}{\$}{\$}via rendering. This dataset, which is considerably larger than similar projective datasets, is publicly offered to the community to enable future research in this direction. We use this dataset to learn in an end-to-end fashion the task of depth estimation from {\$}{\$}{\{}360{\}}^{\{}{\backslash}circ {\}}{\$}{\$}images. We show promising results in our synthesized data as well as in unseen realistic images.",
    isbn="978-3-030-01231-1"
}

